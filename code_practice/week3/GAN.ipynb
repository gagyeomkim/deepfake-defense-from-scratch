{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgudBYomb-W2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input,Dense,Reshape,Flatten,Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization,Activation,LeakyReLU,UpSampling2D,Conv2D\n",
        "from tensorflow.keras.models  import Sequential, Model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#생성자 모델을 만듦\n",
        "generator=Sequential()\n",
        "#128은 몇개의 노드를 중간의 은닉층에 만들것인지\n",
        "#7*7은 뒤에 Upsampling이 있어서 28*28 사이즈 줄인거\n",
        "#0.2는 0말고 0.2로 바꿔라\n",
        "generator.add(Dense(128*7*7,input_dim=100,activation=LeakyReLU(0.2)))\n",
        "#정규화\n",
        "generator.add(BatchNormalization())\n",
        "#일차원에서 2차원으로 바꾸는거\n",
        "generator.add(Reshape((7,7,128)))\n",
        "generator.add(UpSampling2D())\n",
        "#same는 패딩을 자동으로 맞춰줘\n",
        "generator.add(Conv2D(64,kernel_size=5,padding='same'))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Activation(LeakyReLU(0.2)))\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2D(1,kernel_size=5, padding='same', activation='tanh'))\n",
        "\n",
        "#판별자 모델을 만듦\n",
        "discriminator=Sequential()\n",
        "discriminator.add(Conv2D(64,kernel_size=5,strides=2,padding='same',input_shape=(28,28,1)))\n",
        "discriminator.add(Activation(LeakyReLU(0.2)))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Conv2D(128,kernel_size=5,strides=2,padding='same'))\n",
        "discriminator.add(Activation(LeakyReLU(0.2)))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1,activation='sigmoid'))\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer='adam')\n",
        "discriminator.trainable=False\n",
        "\n",
        "#생성자와 판별자 모델을 연결시키는 GAN 모델을 만듦\n",
        "ginput=Input(shape=(100,))\n",
        "dis_output=discriminator(generator(ginput))\n",
        "gan=Model(ginput,dis_output)\n",
        "gan.compile(loss='binary_crossentropy',optimizer='adam')\n",
        "gan.summary()\n",
        "\n",
        "#신경망을 실행시키는 함수 만듦\n",
        "def gan_train(epoch,batch_size,saving_interval):\n",
        "\n",
        "  #MNIST 데이터를 불러옴\n",
        "  (X_train,_), (_,_)=mnist.load_data()\n",
        "  X_train=X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
        "  X_train=(X_train-127.5)/127.5\n",
        "\n",
        "  true=np.ones((batch_size,1))\n",
        "  fake=np.zeros((batch_size,1))\n",
        "\n",
        "  for i in range(epoch):\n",
        "    #실제 데이터를 판별자에 입력하는 부분\n",
        "    idx=np.random.randint(0,X_train.shape[0],batch_size)\n",
        "    imgs=X_train[idx]\n",
        "    d_loss_real=discriminator.train_on_batch(imgs,true)\n",
        "\n",
        "    #가상 이미지를 판별자에 입력하는 부분\n",
        "    noise=np.random.normal(0,1,(batch_size,100))\n",
        "    gen_imgs=generator.predict(noise)\n",
        "    d_loss_fake=discriminator.train_on_batch(gen_imgs,fake)\n",
        "\n",
        "    #판별자와 생성자의 오차를 계산\n",
        "    d_loss=0.5*np.add(d_loss_real,d_loss_fake)\n",
        "    g_loss=gan.train_on_batch(noise,true)\n",
        "\n",
        "    print('epoch:%d' %i, 'd_loss:%.4f' %d_loss, 'g_loss:%.4f' %g_loss)\n",
        "\n",
        "\n",
        "    if i%saving_interval==0:\n",
        "      noise=np.random.normal(0,1,(25,100))\n",
        "      gen_imgs=generator.predict(noise)\n",
        "\n",
        "      #Rescale imges 0-1\n",
        "      gen_imgs=0.5*gen_imgs+0.5\n",
        "\n",
        "      fig,axs=plt.subplots(5,5)\n",
        "      count=0\n",
        "      for j in range(5):\n",
        "        for k in range(5):\n",
        "          axs[j,k].imshow(gen_imgs[count, :, :, 0],cmap='gray')\n",
        "          axs[j,k].axis('off')\n",
        "          count+=1\n",
        "      fig.savefig(\"./gan_mnist_%d.png\"%i)\n",
        "\n",
        "gan_train(2001,32,200)\n",
        "#2000번 반복되고, 배치사이즈는 32, 200번 될때마다 결과를 저장"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# MNIST 데이터셋을 불러옵니다.\n",
        "\n",
        "(X_train, _), (X_test, _) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# 생성자 모델을 만듭니다.\n",
        "autoencoder = Sequential()\n",
        "\n",
        "# 인코딩 부분입니다.\n",
        "autoencoder.add(Conv2D(16, kernel_size=3, padding='same', input_shape=(28,28,1), activation='relu'))\n",
        "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, activation='relu', padding='same'))\n",
        "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
        "\n",
        "# 디코딩 부분입니다.\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
        "autoencoder.add(UpSampling2D())\n",
        "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
        "autoencoder.add(UpSampling2D())\n",
        "autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
        "autoencoder.add(UpSampling2D())\n",
        "autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))\n",
        "\n",
        "# 전체 구조를 확인합니다.\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "OdjEA_06iP19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컴파일 및 학습을 하는 부분입니다.\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test))\n",
        "\n",
        "# 학습된 결과를 출력하는 부분입니다.\n",
        "random_test = np.random.randint(X_test.shape[0], size=5)  # 테스트할 이미지를 랜덤하게 불러옵니다.\n",
        "ae_imgs = autoencoder.predict(X_test)                     # 앞서 만든 오토인코더 모델에 집어 넣습니다.\n",
        "\n",
        "plt.figure(figsize=(7, 2))                         # 출력될 이미지의 크기를 정합니다.\n",
        "\n",
        "for i, image_idx in enumerate(random_test):        # 랜덤하게 뽑은 이미지를 차례로 나열합니다.\n",
        "   ax = plt.subplot(2, 7, i + 1)\n",
        "   plt.imshow(X_test[image_idx].reshape(28, 28))   # 테스트할 이미지를 먼저 그대로 보여줍니다.\n",
        "   ax.axis('off')\n",
        "   ax = plt.subplot(2, 7, 7 + i +1)\n",
        "   plt.imshow(ae_imgs[image_idx].reshape(28, 28))  # 오토인코딩 결과를 다음열에 출력합니다.\n",
        "   ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XyLB2lgKiQuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZ-FPeRgiUew"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}